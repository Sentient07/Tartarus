{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5110 on context None\n",
      "Preallocating 10867/11439 Mb (0.950000) on cuda\n",
      "Mapped name None to device cuda: Tesla K80 (0000:00:1E.0)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as tensor\n",
    "import lasagne\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from lasagne.layers import (Conv2DLayer, DropoutLayer, batch_norm, ReshapeLayer, InputLayer,\n",
    "                            DenseLayer, NonlinearityLayer,ElemwiseSumLayer, MergeLayer,\n",
    "                            TransformerLayer, MergeLayer, Layer, Gate)\n",
    "from lasagne.nonlinearities import softmax, sigmoid, rectify, tanh, identity\n",
    "\n",
    "from IPython.display import display, Image as im\n",
    "from PIL import Image\n",
    "from theano.tensor.nnet.abstract_conv import bilinear_upsampling\n",
    "\n",
    "\n",
    "from lasagne.layers.dense import NINLayer\n",
    "from lasagne.layers.pool import GlobalPoolLayer\n",
    "from lasagne.layers import SliceLayer, TransformerLayer, PadLayer, ElemwiseSumLayer\n",
    "from lasagne.utils import as_tuple\n",
    "from lasagne.objectives import squared_error\n",
    "\n",
    "lr = lasagne.nonlinearities.LeakyRectify(leakiness=0.2)\n",
    "rect = lasagne.nonlinearities.rectify\n",
    "w1 = lasagne.init.Normal(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combating the old lasagne version on Floydhub. The code in this cell belong to Lasagne and hasn't been made available in the release version and belongs to bleeding edge. Floydhub uses the release version and hence, have to copy paste some code.\n",
    "The code that has been borrowed are BatchNormLayer and AffineTransformation Layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import theano.tensor as T\n",
    "from lasagne import init\n",
    "\n",
    "class BatchNormLayer(Layer):\n",
    "\n",
    "    def __init__(self, incoming, axes='auto', epsilon=1e-4, alpha=0.1,\n",
    "                 beta=init.Constant(0), gamma=init.Constant(1),\n",
    "                 mean=init.Constant(0), inv_std=init.Constant(1), **kwargs):\n",
    "        super(BatchNormLayer, self).__init__(incoming, **kwargs)\n",
    "\n",
    "        if axes == 'auto':\n",
    "            # default: normalize over all but the second axis\n",
    "            axes = (0,) + tuple(range(2, len(self.input_shape)))\n",
    "        elif isinstance(axes, int):\n",
    "            axes = (axes,)\n",
    "        self.axes = axes\n",
    "\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "\n",
    "        # create parameters, ignoring all dimensions in axes\n",
    "        shape = [size for axis, size in enumerate(self.input_shape)\n",
    "                 if axis not in self.axes]\n",
    "        if any(size is None for size in shape):\n",
    "            raise ValueError(\"BatchNormLayer needs specified input sizes for \"\n",
    "                             \"all axes not normalized over.\")\n",
    "        if beta is None:\n",
    "            self.beta = None\n",
    "        else:\n",
    "            self.beta = self.add_param(beta, shape, 'beta',\n",
    "                                       trainable=True, regularizable=False)\n",
    "        if gamma is None:\n",
    "            self.gamma = None\n",
    "        else:\n",
    "            self.gamma = self.add_param(gamma, shape, 'gamma',\n",
    "                                        trainable=True, regularizable=True)\n",
    "        self.mean = self.add_param(mean, shape, 'mean',\n",
    "                                   trainable=False, regularizable=False)\n",
    "        self.inv_std = self.add_param(inv_std, shape, 'inv_std',\n",
    "                                      trainable=False, regularizable=False)\n",
    "\n",
    "    def get_output_for(self, input, deterministic=False,\n",
    "                       batch_norm_use_averages=None,\n",
    "                       batch_norm_update_averages=None, **kwargs):\n",
    "        input_mean = input.mean(self.axes)\n",
    "        input_inv_std = tensor.inv(tensor.sqrt(input.var(self.axes) + self.epsilon))\n",
    "\n",
    "        # Decide whether to use the stored averages or mini-batch statistics\n",
    "        if batch_norm_use_averages is None:\n",
    "            batch_norm_use_averages = deterministic\n",
    "        use_averages = batch_norm_use_averages\n",
    "\n",
    "        if use_averages:\n",
    "            mean = self.mean\n",
    "            inv_std = self.inv_std\n",
    "        else:\n",
    "            mean = input_mean\n",
    "            inv_std = input_inv_std\n",
    "\n",
    "        # Decide whether to update the stored averages\n",
    "        if batch_norm_update_averages is None:\n",
    "            batch_norm_update_averages = not deterministic\n",
    "        update_averages = batch_norm_update_averages\n",
    "\n",
    "        if update_averages:\n",
    "            # Trick: To update the stored statistics, we create memory-aliased\n",
    "            # clones of the stored statistics:\n",
    "            running_mean = theano.clone(self.mean, share_inputs=False)\n",
    "            running_inv_std = theano.clone(self.inv_std, share_inputs=False)\n",
    "            # set a default update for them:\n",
    "            running_mean.default_update = ((1 - self.alpha) * running_mean +\n",
    "                                           self.alpha * input_mean)\n",
    "            running_inv_std.default_update = ((1 - self.alpha) *\n",
    "                                              running_inv_std +\n",
    "                                              self.alpha * input_inv_std)\n",
    "            # and make sure they end up in the graph without participating in\n",
    "            # the computation (this way their default_update will be collected\n",
    "            # and applied, but the computation will be optimized away):\n",
    "            mean += 0 * running_mean\n",
    "            inv_std += 0 * running_inv_std\n",
    "\n",
    "        # prepare dimshuffle pattern inserting broadcastable axes as needed\n",
    "        param_axes = iter(range(input.ndim - len(self.axes)))\n",
    "        pattern = ['x' if input_axis in self.axes\n",
    "                   else next(param_axes)\n",
    "                   for input_axis in range(input.ndim)]\n",
    "\n",
    "        # apply dimshuffle pattern to all parameters\n",
    "        beta = 0 if self.beta is None else self.beta.dimshuffle(pattern)\n",
    "        gamma = 1 if self.gamma is None else self.gamma.dimshuffle(pattern)\n",
    "        mean = mean.dimshuffle(pattern)\n",
    "        inv_std = inv_std.dimshuffle(pattern)\n",
    "\n",
    "        # normalize\n",
    "        normalized = (input - mean) * (gamma * inv_std) + beta\n",
    "        return normalized\n",
    "\n",
    "\n",
    "def batch_norm(layer, **kwargs):\n",
    "    nonlinearity = getattr(layer, 'nonlinearity', None)\n",
    "    if nonlinearity is not None:\n",
    "        layer.nonlinearity = nonlinearities.identity\n",
    "    if hasattr(layer, 'b') and layer.b is not None:\n",
    "        del layer.params[layer.b]\n",
    "        layer.b = None\n",
    "    bn_name = (kwargs.pop('name', None) or\n",
    "               (getattr(layer, 'name', None) and layer.name + '_bn'))\n",
    "    layer = BatchNormLayer(layer, name=bn_name, **kwargs)\n",
    "    if nonlinearity is not None:\n",
    "        from .special import NonlinearityLayer\n",
    "        nonlin_name = bn_name and bn_name + '_nonlin'\n",
    "        layer = NonlinearityLayer(layer, nonlinearity, name=nonlin_name)\n",
    "        return layer\n",
    "    \n",
    "\n",
    "class Dconv2DLayer(lasagne.layers.Layer):\n",
    "\n",
    "    def __init__(self, incoming, num_filters, filter_size, stride=1, pad=0,\n",
    "            nonlinearity=rect, **kwargs):\n",
    "        super(Dconv2DLayer, self).__init__(incoming, **kwargs)\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_size = lasagne.utils.as_tuple(filter_size, 2, int)\n",
    "        self.stride = lasagne.utils.as_tuple(stride, 2, int)\n",
    "        self.pad = lasagne.utils.as_tuple(pad, 2, int)\n",
    "        self.W = self.add_param(lasagne.init.Normal(0.05),\n",
    "                (self.input_shape[1], num_filters) + self.filter_size,\n",
    "                name='W')\n",
    "        self.b = self.add_param(lasagne.init.Constant(0),\n",
    "                (num_filters,),\n",
    "                name='b')\n",
    "        if nonlinearity is None:\n",
    "            nonlinearity = lasagne.nonlinearities.identity\n",
    "        self.nonlinearity = nonlinearity\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        shape = tuple(i*s - 2*p + f - 1\n",
    "                for i, s, p, f in zip(input_shape[2:],\n",
    "                                      self.stride,\n",
    "                                      self.pad,\n",
    "                                      self.filter_size))\n",
    "        return (input_shape[0], self.num_filters) + shape\n",
    "\n",
    "    def get_output_for(self, input, **kwargs):\n",
    "        op = tensor.nnet.abstract_conv.AbstractConv2d_gradInputs(\n",
    "            imshp=self.output_shape,\n",
    "            kshp=(self.input_shape[1], self.num_filters) + self.filter_size,\n",
    "            subsample=self.stride, border_mode=self.pad)\n",
    "        conved = op(self.W, input, self.output_shape[2:])\n",
    "        if self.b is not None:\n",
    "            conved += self.b.dimshuffle('x', 0, 'x', 'x')\n",
    "        return self.nonlinearity(conved)\n",
    "    \n",
    "def _linspace(start, stop, num):\n",
    "    # Theano linspace. Behaves similar to np.linspace\n",
    "    start = T.cast(start, theano.config.floatX)\n",
    "    stop = T.cast(stop, theano.config.floatX)\n",
    "    num = T.cast(num, theano.config.floatX)\n",
    "    step = (stop-start)/(num-1)\n",
    "    return T.arange(num, dtype=theano.config.floatX)*step+start\n",
    "    \n",
    "def _meshgrid(height, width):\n",
    "    # This function is the grid generator from eq. (1) in reference [1].\n",
    "    # It is equivalent to the following numpy code:\n",
    "    #  x_t, y_t = np.meshgrid(np.linspace(-1, 1, width),\n",
    "    #                         np.linspace(-1, 1, height))\n",
    "    #  ones = np.ones(np.prod(x_t.shape))\n",
    "    #  grid = np.vstack([x_t.flatten(), y_t.flatten(), ones])\n",
    "    # It is implemented in Theano instead to support symbolic grid sizes.\n",
    "    # Note: If the image size is known at layer construction time, we could\n",
    "    # compute the meshgrid offline in numpy instead of doing it dynamically\n",
    "    # in Theano. However, it hardly affected performance when we tried.\n",
    "    x_t = T.dot(T.ones((height, 1)),\n",
    "                _linspace(-1.0, 1.0, width).dimshuffle('x', 0))\n",
    "    y_t = T.dot(_linspace(-1.0, 1.0, height).dimshuffle(0, 'x'),\n",
    "                T.ones((1, width)))\n",
    "\n",
    "    x_t_flat = x_t.reshape((1, -1))\n",
    "    y_t_flat = y_t.reshape((1, -1))\n",
    "    ones = T.ones_like(x_t_flat)\n",
    "    grid = T.concatenate([x_t_flat, y_t_flat, ones], axis=0)\n",
    "    return grid\n",
    "    \n",
    "def _transform_affine(theta, input, downsample_factor, border_mode):\n",
    "    num_batch, num_channels, height, width = input.shape\n",
    "    theta = T.reshape(theta, (-1, 2, 3))\n",
    "\n",
    "    # grid of (x_t, y_t, 1), eq (1) in ref [1]\n",
    "    out_height = T.cast(height // downsample_factor[0], 'int64')\n",
    "    out_width = T.cast(width // downsample_factor[1], 'int64')\n",
    "    grid = _meshgrid(out_height, out_width)\n",
    "\n",
    "    # Transform A x (x_t, y_t, 1)^T -> (x_s, y_s)\n",
    "    T_g = T.dot(theta, grid)\n",
    "    x_s = T_g[:, 0]\n",
    "    y_s = T_g[:, 1]\n",
    "    x_s_flat = x_s.flatten()\n",
    "    y_s_flat = y_s.flatten()\n",
    "\n",
    "    # dimshuffle input to  (bs, height, width, channels)\n",
    "    input_dim = input.dimshuffle(0, 2, 3, 1)\n",
    "    input_transformed = _interpolate(\n",
    "        input_dim, x_s_flat, y_s_flat,\n",
    "        out_height, out_width, border_mode)\n",
    "\n",
    "    output = T.reshape(\n",
    "        input_transformed, (num_batch, out_height, out_width, num_channels))\n",
    "    output = output.dimshuffle(0, 3, 1, 2)  # dimshuffle to conv format\n",
    "    return output\n",
    "\n",
    "\n",
    "class TransformerLayer(MergeLayer):\n",
    "\n",
    "    def __init__(self, incoming, localization_network, downsample_factor=1,\n",
    "                 border_mode='nearest', **kwargs):\n",
    "        super(TransformerLayer, self).__init__(\n",
    "            [incoming, localization_network], **kwargs)\n",
    "        self.downsample_factor = as_tuple(downsample_factor, 2)\n",
    "        self.border_mode = border_mode\n",
    "\n",
    "        input_shp, loc_shp = self.input_shapes\n",
    "\n",
    "        if loc_shp[-1] != 6 or len(loc_shp) != 2:\n",
    "            raise ValueError(\"The localization network must have \"\n",
    "                             \"output shape: (batch_size, 6)\")\n",
    "        if len(input_shp) != 4:\n",
    "            raise ValueError(\"The input network must have a 4-dimensional \"\n",
    "                             \"output shape: (batch_size, num_input_channels, \"\n",
    "                             \"input_rows, input_columns)\")\n",
    "\n",
    "    def get_output_shape_for(self, input_shapes):\n",
    "        shape = input_shapes[0]\n",
    "        factors = self.downsample_factor\n",
    "        return (shape[:2] + tuple(None if s is None else int(s // f)\n",
    "                                  for s, f in zip(shape[2:], factors)))\n",
    "\n",
    "    def get_output_for(self, inputs, **kwargs):\n",
    "        # see eq. (1) and sec 3.1 in [1]\n",
    "        input, theta = inputs\n",
    "        return _transform_affine(theta, input, self.downsample_factor,\n",
    "self.border_mode)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DotLayer(lasagne.layers.Layer):\n",
    "    '''\n",
    "    A simple Layer to perform a dot product between two Lasagne Layers.\n",
    "    '''\n",
    "    def __init__(self, incoming, num_units, W=lasagne.init.Normal(0.01), nonlinearities=None, **kwargs):\n",
    "        super(DotLayer, self).__init__(incoming, **kwargs)\n",
    "        num_inputs = self.input_shape[1]\n",
    "        self.num_units = num_units\n",
    "        self.W = self.add_param(W, (num_inputs, num_units), name='W')\n",
    "        self.nonlinearities = nonlinearities\n",
    "\n",
    "    def get_output_for(self, input, **kwargs):\n",
    "        return self.nonlinearities(tensor.dot(input, self.W))\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], self.num_units)\n",
    "\n",
    "\n",
    "class ComplimentLayer(lasagne.layers.Layer):\n",
    "    '''\n",
    "    Perform a compliment wrt 1.\n",
    "    Parameter \n",
    "    ---------\n",
    "    incoming : A Lasagne Layer\n",
    "    \n",
    "    returns : ones_like(input) - input\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, incoming, **kwargs):\n",
    "        super(ComplimentLayer, self).__init__(incoming, **kwargs)\n",
    "        self.incoming = incoming\n",
    "    \n",
    "    def get_ouput_shape_for(self, input_shape):\n",
    "        return input_shape\n",
    "    \n",
    "    def get_output_for(self, input):\n",
    "        ones = tensor.ones(input.shape)\n",
    "        return ones - input\n",
    "\n",
    "\n",
    "# Edited version of LSTM layer to give the h and c vector of current state\n",
    "# Code for the following class is borrowed Joel Moniz's implementation shared in Lasagne Google Groups\n",
    "\n",
    "class ExposedLSTMLayer(MergeLayer):\n",
    "\n",
    "    def __init__(self, incoming, num_units,\n",
    "                 ingate=Gate(),\n",
    "                 forgetgate=Gate(),\n",
    "                 cell=Gate(W_cell=None, nonlinearity=tanh),\n",
    "                 outgate=Gate(),\n",
    "                 nonlinearity=tanh,\n",
    "                 cell_init=lasagne.init.Constant(0.),\n",
    "                 hid_init=lasagne.init.Constant(0.),\n",
    "                 backwards=False,\n",
    "                 learn_init=False,\n",
    "                 peepholes=True,\n",
    "                 gradient_steps=-1,\n",
    "                 grad_clipping=0,\n",
    "                 unroll_scan=False,\n",
    "                 precompute_input=True,\n",
    "                 mask_input=None,\n",
    "                 only_return_final=False,\n",
    "                 **kwargs):\n",
    "\n",
    "        # This layer inherits from a MergeLayer, because it can have four\n",
    "        # inputs - the layer input, the mask, the initial hidden state and the\n",
    "        # inital cell state. We will just provide the layer input as incomings,\n",
    "        # unless a mask input, inital hidden state or initial cell state was\n",
    "        # provided.\n",
    "        incomings = [incoming]\n",
    "        self.mask_incoming_index = -1\n",
    "        self.hid_init_incoming_index = -1\n",
    "        self.cell_init_incoming_index = -1\n",
    "        if mask_input is not None:\n",
    "            incomings.append(mask_input)\n",
    "            self.mask_incoming_index = len(incomings)-1\n",
    "        if isinstance(hid_init, Layer):\n",
    "            incomings.append(hid_init)\n",
    "            self.hid_init_incoming_index = len(incomings)-1\n",
    "        if isinstance(cell_init, Layer):\n",
    "            incomings.append(cell_init)\n",
    "            self.cell_init_incoming_index = len(incomings)-1\n",
    "\n",
    "        # Initialize parent layer\n",
    "        super(ExposedLSTMLayer, self).__init__(incomings, **kwargs)\n",
    "\n",
    "        # If the provided nonlinearity is None, make it linear\n",
    "        if nonlinearity is None:\n",
    "            self.nonlinearity = identity\n",
    "        else:\n",
    "            self.nonlinearity = nonlinearity\n",
    "\n",
    "        self.learn_init = learn_init\n",
    "        self.num_units = num_units\n",
    "        self.backwards = backwards\n",
    "        self.peepholes = peepholes\n",
    "        self.gradient_steps = gradient_steps\n",
    "        self.grad_clipping = grad_clipping\n",
    "        self.unroll_scan = unroll_scan\n",
    "        self.precompute_input = precompute_input\n",
    "        self.only_return_final = only_return_final\n",
    "\n",
    "        if unroll_scan and gradient_steps != -1:\n",
    "            raise ValueError(\n",
    "                \"Gradient steps must be -1 when unroll_scan is true.\")\n",
    "\n",
    "        # Retrieve the dimensionality of the incoming layer\n",
    "        input_shape = self.input_shapes[0]\n",
    "\n",
    "        if unroll_scan and input_shape[1] is None:\n",
    "            raise ValueError(\"Input sequence length cannot be specified as \"\n",
    "                             \"None when unroll_scan is True\")\n",
    "\n",
    "        num_inputs = np.prod(input_shape[2:])\n",
    "\n",
    "        def add_gate_params(gate, gate_name):\n",
    "            \"\"\" Convenience function for adding layer parameters from a Gate\n",
    "            instance. \"\"\"\n",
    "            return (self.add_param(gate.W_in, (num_inputs, num_units),\n",
    "                                   name=\"W_in_to_{}\".format(gate_name)),\n",
    "                    self.add_param(gate.W_hid, (num_units, num_units),\n",
    "                                   name=\"W_hid_to_{}\".format(gate_name)),\n",
    "                    self.add_param(gate.b, (num_units,),\n",
    "                                   name=\"b_{}\".format(gate_name),\n",
    "                                   regularizable=False),\n",
    "                    gate.nonlinearity)\n",
    "\n",
    "        # Add in parameters from the supplied Gate instances\n",
    "        (self.W_in_to_ingate, self.W_hid_to_ingate, self.b_ingate,\n",
    "         self.nonlinearity_ingate) = add_gate_params(ingate, 'ingate')\n",
    "\n",
    "        (self.W_in_to_forgetgate, self.W_hid_to_forgetgate, self.b_forgetgate,\n",
    "         self.nonlinearity_forgetgate) = add_gate_params(forgetgate,\n",
    "                                                         'forgetgate')\n",
    "\n",
    "        (self.W_in_to_cell, self.W_hid_to_cell, self.b_cell,\n",
    "         self.nonlinearity_cell) = add_gate_params(cell, 'cell')\n",
    "\n",
    "        (self.W_in_to_outgate, self.W_hid_to_outgate, self.b_outgate,\n",
    "         self.nonlinearity_outgate) = add_gate_params(outgate, 'outgate')\n",
    "\n",
    "        # If peephole (cell to gate) connections were enabled, initialize\n",
    "        # peephole connections.  These are elementwise products with the cell\n",
    "        # state, so they are represented as vectors.\n",
    "        if self.peepholes:\n",
    "            self.W_cell_to_ingate = self.add_param(\n",
    "                ingate.W_cell, (num_units, ), name=\"W_cell_to_ingate\")\n",
    "\n",
    "            self.W_cell_to_forgetgate = self.add_param(\n",
    "                forgetgate.W_cell, (num_units, ), name=\"W_cell_to_forgetgate\")\n",
    "\n",
    "            self.W_cell_to_outgate = self.add_param(\n",
    "                outgate.W_cell, (num_units, ), name=\"W_cell_to_outgate\")\n",
    "\n",
    "        # Setup initial values for the cell and the hidden units\n",
    "        if isinstance(cell_init, Layer):\n",
    "            self.cell_init = cell_init\n",
    "        else:\n",
    "            self.cell_init = self.add_param(\n",
    "                cell_init, (1, num_units), name=\"cell_init\",\n",
    "                trainable=learn_init, regularizable=False)\n",
    "\n",
    "        if isinstance(hid_init, Layer):\n",
    "            self.hid_init = hid_init\n",
    "        else:\n",
    "            self.hid_init = self.add_param(\n",
    "                hid_init, (1, self.num_units), name=\"hid_init\",\n",
    "                trainable=learn_init, regularizable=False)\n",
    "\n",
    "    def get_output_shape_for(self, input_shapes):\n",
    "        # The shape of the input to this layer will be the first element\n",
    "        # of input_shapes, whether or not a mask input is being used.\n",
    "        input_shape = input_shapes[0]\n",
    "        # When only_return_final is true, the second (sequence step) dimension\n",
    "        # will be flattened\n",
    "        if self.only_return_final:\n",
    "            return input_shape[0], 2*self.num_units\n",
    "        # Otherwise, the shape will be (n_batch, n_steps, num_units)\n",
    "        else:\n",
    "            return input_shape[0], input_shape[1], 2*self.num_units\n",
    "\n",
    "    def get_output_for(self, inputs, **kwargs):\n",
    "\n",
    "        # Retrieve the layer input\n",
    "        input = inputs[0]\n",
    "        # Retrieve the mask when it is supplied\n",
    "        mask = None\n",
    "        hid_init = None\n",
    "        cell_init = None\n",
    "        if self.mask_incoming_index > 0:\n",
    "            mask = inputs[self.mask_incoming_index]\n",
    "        if self.hid_init_incoming_index > 0:\n",
    "            hid_init = inputs[self.hid_init_incoming_index]\n",
    "        if self.cell_init_incoming_index > 0:\n",
    "            cell_init = inputs[self.cell_init_incoming_index]\n",
    "\n",
    "        # Treat all dimensions after the second as flattened feature dimensions\n",
    "        if input.ndim > 3:\n",
    "            input = tensor.flatten(input, 3)\n",
    "\n",
    "        # Because scan iterates over the first dimension we dimshuffle to\n",
    "        # (n_time_steps, n_batch, n_features)\n",
    "        input = input.dimshuffle(1, 0, 2)\n",
    "        seq_len, num_batch, _ = input.shape\n",
    "\n",
    "        # Stack input weight matrices into a (num_inputs, 4*num_units)\n",
    "        # matrix, which speeds up computation\n",
    "        W_in_stacked = tensor.concatenate(\n",
    "            [self.W_in_to_ingate, self.W_in_to_forgetgate,\n",
    "             self.W_in_to_cell, self.W_in_to_outgate], axis=1)\n",
    "\n",
    "        # Same for hidden weight matrices\n",
    "        W_hid_stacked = tensor.concatenate(\n",
    "            [self.W_hid_to_ingate, self.W_hid_to_forgetgate,\n",
    "             self.W_hid_to_cell, self.W_hid_to_outgate], axis=1)\n",
    "\n",
    "        # Stack biases into a (4*num_units) vector\n",
    "        b_stacked = tensor.concatenate(\n",
    "            [self.b_ingate, self.b_forgetgate,\n",
    "             self.b_cell, self.b_outgate], axis=0)\n",
    "\n",
    "        if self.precompute_input:\n",
    "            # Because the input is given for all time steps, we can\n",
    "            # precompute_input the inputs dot weight matrices before scanning.\n",
    "            # W_in_stacked is (n_features, 4*num_units). input is then\n",
    "            # (n_time_steps, n_batch, 4*num_units).\n",
    "            input = tensor.dot(input, W_in_stacked) + b_stacked\n",
    "\n",
    "        # At each call to scan, input_n will be (n_time_steps, 4*num_units).\n",
    "        # We define a slicing function that extract the input to each LSTM gate\n",
    "        def slice_w(x, n):\n",
    "            return x[:, n*self.num_units:(n+1)*self.num_units]\n",
    "\n",
    "        # Create single recurrent computation step function\n",
    "        # input_n is the n'th vector of the input\n",
    "        def step(input_n, cell_previous, hid_previous, *args):\n",
    "            if not self.precompute_input:\n",
    "                input_n = tensor.dot(input_n, W_in_stacked) + b_stacked\n",
    "\n",
    "            # Calculate gates pre-activations and slice\n",
    "            gates = input_n + tensor.dot(hid_previous, W_hid_stacked)\n",
    "\n",
    "            # Clip gradients\n",
    "            if self.grad_clipping:\n",
    "                gates = theano.gradient.grad_clip(\n",
    "                    gates, -self.grad_clipping, self.grad_clipping)\n",
    "\n",
    "            # Extract the pre-activation gate values\n",
    "            ingate = slice_w(gates, 0)\n",
    "            forgetgate = slice_w(gates, 1)\n",
    "            cell_input = slice_w(gates, 2)\n",
    "            outgate = slice_w(gates, 3)\n",
    "\n",
    "            if self.peepholes:\n",
    "                # Compute peephole connections\n",
    "                ingate += cell_previous*self.W_cell_to_ingate\n",
    "                forgetgate += cell_previous*self.W_cell_to_forgetgate\n",
    "\n",
    "            # Apply nonlinearities\n",
    "            ingate = self.nonlinearity_ingate(ingate)\n",
    "            forgetgate = self.nonlinearity_forgetgate(forgetgate)\n",
    "            cell_input = self.nonlinearity_cell(cell_input)\n",
    "\n",
    "            # Compute new cell value\n",
    "            cell = forgetgate*cell_previous + ingate*cell_input\n",
    "\n",
    "            if self.peepholes:\n",
    "                outgate += cell*self.W_cell_to_outgate\n",
    "            outgate = self.nonlinearity_outgate(outgate)\n",
    "\n",
    "            # Compute new hidden unit activation\n",
    "            hid = outgate*self.nonlinearity(cell)\n",
    "            return [cell, hid]\n",
    "\n",
    "        def step_masked(input_n, mask_n, cell_previous, hid_previous, *args):\n",
    "            cell, hid = step(input_n, cell_previous, hid_previous, *args)\n",
    "\n",
    "            # Skip over any input with mask 0 by copying the previous\n",
    "            # hidden state; proceed normally for any input with mask 1.\n",
    "            cell = tensor.switch(mask_n, cell, cell_previous)\n",
    "            hid = tensor.switch(mask_n, hid, hid_previous)\n",
    "\n",
    "            return [cell, hid]\n",
    "\n",
    "        if mask is not None:\n",
    "            # mask is given as (batch_size, seq_len). Because scan iterates\n",
    "            # over first dimension, we dimshuffle to (seq_len, batch_size) and\n",
    "            # add a broadcastable dimension\n",
    "            mask = mask.dimshuffle(1, 0, 'x')\n",
    "            sequences = [input, mask]\n",
    "            step_fun = step_masked\n",
    "        else:\n",
    "            sequences = input\n",
    "            step_fun = step\n",
    "\n",
    "        ones = tensor.ones((num_batch, 1))\n",
    "        if not isinstance(self.cell_init, Layer):\n",
    "            # Dot against a 1s vector to repeat to shape (num_batch, num_units)\n",
    "            cell_init = tensor.dot(ones, self.cell_init)\n",
    "\n",
    "        if not isinstance(self.hid_init, Layer):\n",
    "            # Dot against a 1s vector to repeat to shape (num_batch, num_units)\n",
    "            hid_init = tensor.dot(ones, self.hid_init)\n",
    "\n",
    "        # The hidden-to-hidden weight matrix is always used in step\n",
    "        non_seqs = [W_hid_stacked]\n",
    "        # The \"peephole\" weight matrices are only used when self.peepholes=True\n",
    "        if self.peepholes:\n",
    "            non_seqs += [self.W_cell_to_ingate,\n",
    "                         self.W_cell_to_forgetgate,\n",
    "                         self.W_cell_to_outgate]\n",
    "\n",
    "        # When we aren't precomputing the input outside of scan, we need to\n",
    "        # provide the input weights and biases to the step function\n",
    "        if not self.precompute_input:\n",
    "            non_seqs += [W_in_stacked, b_stacked]\n",
    "\n",
    "        if self.unroll_scan:\n",
    "            # Retrieve the dimensionality of the incoming layer\n",
    "            input_shape = self.input_shapes[0]\n",
    "            # Explicitly unroll the recurrence instead of using scan\n",
    "            cell_out, hid_out = lasagne.utils.unroll_scan(\n",
    "                fn=step_fun,\n",
    "                sequences=sequences,\n",
    "                outputs_info=[cell_init, hid_init],\n",
    "                go_backwards=self.backwards,\n",
    "                non_sequences=non_seqs,\n",
    "                n_steps=input_shape[1])\n",
    "        else:\n",
    "            # Scan op iterates over first dimension of input and repeatedly\n",
    "            # applies the step function\n",
    "            cell_out, hid_out = theano.scan(\n",
    "                fn=step_fun,\n",
    "                sequences=sequences,\n",
    "                outputs_info=[cell_init, hid_init],\n",
    "                go_backwards=self.backwards,\n",
    "                truncate_gradient=self.gradient_steps,\n",
    "                non_sequences=non_seqs,\n",
    "                strict=True)[0]\n",
    "\n",
    "        # When it is requested that we only return the final sequence step,\n",
    "        # we need to slice it out immediately after scan is applied\n",
    "        if self.only_return_final:\n",
    "            cell_out = cell_out[-1]\n",
    "            hid_out = hid_out[-1]\n",
    "        else:\n",
    "            # dimshuffle back to (n_batch, n_time_steps, n_features))\n",
    "            cell_out = cell_out.dimshuffle(1, 0, 2)\n",
    "            hid_out = hid_out.dimshuffle(1, 0, 2)\n",
    "\n",
    "            # if scan is backward reverse the output\n",
    "            if self.backwards:\n",
    "                hid_out = hid_out[:, ::-1]\n",
    "                cell_out = cell_out[:, ::-1]\n",
    "\n",
    "        return tensor.concatenate([cell_out, hid_out], axis=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This layer has been taken from Lasagne and some modifications has been made.\n",
    "Lasagne currently does not take care of broadcasting and I have made a Pull Request(https://github.com/Lasagne/Lasagne/pull/854)  for desired broadcasting work to be done at the InputLayer level.\n",
    "tl;dr of the issue is, in Theano you will have to explicitly handle the broadcasting pattern for each dimension of a tensor. When you do so, you would lose the exact instance of that Variable. Hence, in Lasagne it is intended to do the broadcasting work at the creation of the Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class ElemwiseMergeLayer(MergeLayer):\n",
    "    def __init__(self, incomings, merge_function, broadcastable=None, cropping=None, **kwargs):\n",
    "        super(ElemwiseMergeLayer, self).__init__(incomings, **kwargs)\n",
    "        self.merge_function = merge_function\n",
    "        self.cropping = cropping\n",
    "        self.broadcastable = broadcastable\n",
    "\n",
    "    def get_output_shape_for(self, input_shapes):\n",
    "\n",
    "        # Infer the output shape by grabbing, for each axis, the first\n",
    "        # input size that is not `None` (if there is any)\n",
    "        output_shape = tuple([max(i, j) for i, j in zip(input_shapes[0], input_shapes[1])])\n",
    "\n",
    "        return output_shape\n",
    "\n",
    "    def get_output_for(self, inputs, **kwargs):\n",
    "        # modify broadcasting pattern.\n",
    "        if self.broadcastable:\n",
    "            if self.broadcastable == 1:\n",
    "                inputs[0] = tensor.addbroadcast(inputs[0], 1)\n",
    "            elif self.broadcastable == 2:\n",
    "                inputs[1] = tensor.addbroadcast(inputs[1], 1)\n",
    "\n",
    "        output = None\n",
    "        for input in inputs:\n",
    "            if output is not None:\n",
    "                output = self.merge_function(output, input)\n",
    "            else:\n",
    "                output = input\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extracting \n",
    "import cPickle\n",
    "import tarfile\n",
    "\n",
    "dataset_path = '/output/cifar-100-python/train'\n",
    "    \n",
    "path_to_zip_file = '/input/cifar-100/python.tar.gz'\n",
    "directory_to_extract_to = '/output/'\n",
    "\n",
    "zip_ref = tarfile.open(path_to_zip_file, 'r')\n",
    "zip_ref.extractall(directory_to_extract_to)\n",
    "zip_ref.close()\n",
    "\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = cPickle.load(fo)\n",
    "    return dict\n",
    "\n",
    "cifar_data = unpickle(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "(50000, 32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMwAAADGCAYAAACeuW+UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/BaAFAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff8d07dd250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualisation cell\n",
    "# plotting some samples from the original data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def normalise(im):\n",
    "    im = im / np.float32(127.5) - np.float32(1.)\n",
    "    return im\n",
    "\n",
    "def denormalise(im, tanh=True):\n",
    "    im = ((im + np.float32(1.0)) * np.float32(127.5)).astype(np.uint8)\n",
    "    if tanh:\n",
    "        im = im.transpose(0, 2, 3, 1)\n",
    "    return im\n",
    "generated_image = generate_im_func()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pylab\n",
    "\n",
    "reshaped_image = cifar_data['data'].reshape(50000, 3, 32, 32)\n",
    "transposed_image = reshaped_image.transpose(0, 2, 3, 1)\n",
    "\n",
    "fig, axes1 = plt.subplots(5, 5, figsize=(3, 3))\n",
    "# axes1.set_axis_off()\n",
    "# axes1.imshow(reshaped_image[10])\n",
    "# fig.imshow(reshaped_image[10])\n",
    "for j in range(5):\n",
    "    for k in range(5):\n",
    "        i = np.random.choice(range(len(generated_image)))\n",
    "        axes1[j][k].set_axis_off()\n",
    "        axes1[j][k].imshow(denormalise(generated_image[i:i+1])[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_units = 100\n",
    "\n",
    "def gen_bg(back_noise):\n",
    "    net1 = batch_norm(DenseLayer(back_noise, 8192, W=w1))\n",
    "    net1_r = ReshapeLayer(net1, ([0], 512, 4, 4))\n",
    "    net2 = batch_norm(Dconv2DLayer(net1_r, 256, 3, stride=1, pad=1))\n",
    "    net3 = batch_norm(Dconv2DLayer(net2, 128, 3, stride=2, pad=1))\n",
    "    # 8 * 8\n",
    "    net4 = batch_norm(Dconv2DLayer(net3, 64, 3, stride=2, pad=1))\n",
    "    # 16 * 16\n",
    "    net5 = Dconv2DLayer(net4, 3, 3, stride=2, pad=1, nonlinearity=tanh)\n",
    "    # 3 * 32 * 32\n",
    "    return net5\n",
    "\n",
    "# Foreground Generator\n",
    "def gen_fc(y_t):\n",
    "    net1 = batch_norm(DenseLayer(y_t, 8192, W=w1))\n",
    "    net1_r = ReshapeLayer(net1, ([0], 512, 4, 4))\n",
    "    net2 = batch_norm(Dconv2DLayer(net1_r, 512, 3, pad=1))\n",
    "    net3 = batch_norm(Dconv2DLayer(net2, 256, 3, stride=2, pad=1))\n",
    "    # 8 * 8\n",
    "    net4 = batch_norm(Dconv2DLayer(net3, 128, 3, stride=2, pad=1))\n",
    "    # 16 * 16\n",
    "    return net4\n",
    "\n",
    "def gen_fi(fc_out):\n",
    "    net1 = batch_norm(Dconv2DLayer(fc_out, 3, 3, stride=2, pad=1))\n",
    "    return net1\n",
    "\n",
    "# Foreground mask\n",
    "def gen_fmask(fc_out):\n",
    "    net1 = batch_norm(Dconv2DLayer(fc_out, 1, 3, stride=2, pad=1, nonlinearity=sigmoid))\n",
    "    return net1\n",
    "\n",
    "# Discriminator\n",
    "def build_desc(inp):\n",
    "    net0= InputLayer((None, 3, 32, 32), input_var=inp)\n",
    "    # 32 * 32\n",
    "    net1 = batch_norm(Conv2DLayer(net0, 96, 3, stride=2, pad='same', W=w1, nonlinearity=lr))\n",
    "    # 16 * 16\n",
    "    net2 = batch_norm(Conv2DLayer(net1, 192, 3, stride=2, pad='same', W=w1, nonlinearity=lr))\n",
    "\n",
    "    # 8 * 8\n",
    "    net3 = batch_norm(Conv2DLayer(net2, 192, 3, pad='same', W=w1, nonlinearity=lr))\n",
    "\n",
    "    # 6 * 6\n",
    "    net4 = batch_norm(NINLayer(net3, 192, W=w1, nonlinearity=lr))\n",
    "    net5 = batch_norm(NINLayer(net4, 192, W=w1, nonlinearity=lr))\n",
    "    net6 = GlobalPoolLayer(net5)\n",
    "    net7 = DenseLayer(net6, 1, W=w1, nonlinearity=sigmoid)\n",
    "    return net7, net6\n",
    "\n",
    "def construct_gen(noise_1, noise_2, batch_size=100):\n",
    "    # There are two time steps considered for this model, so two LSTMs\n",
    "    # Reshape noises\n",
    "    noise1_rshp = noise_1.dimshuffle(0, 'x', 1)\n",
    "    noise2_rshp = noise_2.dimshuffle(0, 'x', 1)\n",
    "    lstm1_inp = InputLayer((None, 1, 100), input_var=noise1_rshp)\n",
    "    lstm2_inp = InputLayer((None, 1, 100), input_var=noise2_rshp)\n",
    "\n",
    "    lstm2 = ExposedLSTMLayer(lstm2_inp, 100)\n",
    "    lstm2_h = SliceLayer(lstm2, indices=slice(num_units, None), axis=-1)\n",
    "    lstm2_reshape = ReshapeLayer(lstm2_h, (batch_size, 100))\n",
    "\n",
    "    print(\"LSTM2's output is \" + str(lstm2_reshape.output_shape))\n",
    "\n",
    "    build_bg = gen_bg(lstm1_inp)\n",
    "    build_gfc = gen_fc(lstm2_reshape)\n",
    "    build_gif = gen_fi(build_gfc)\n",
    "    build_gfmask = gen_fmask(build_gfc)\n",
    "    \n",
    "    # Affine transformation and pasting with Background Image\n",
    "    a_t = DenseLayer(lstm2_reshape, num_units=6, W=w1) #6 dim output\n",
    "    m_t_hat = NonlinearityLayer(PadLayer(TransformerLayer(build_gfmask, a_t, downsample_factor=2), 8), nonlinearity=tanh)\n",
    "    f_t_hat = NonlinearityLayer(PadLayer(TransformerLayer(build_gif, a_t, downsample_factor=2), 8), nonlinearity=tanh)\n",
    "    \n",
    "    prior = ElemwiseMergeLayer([m_t_hat, f_t_hat], merge_function=tensor.mul, broadcastable=1)\n",
    "    posterior = ElemwiseMergeLayer([ComplimentLayer(m_t_hat), build_bg], merge_function=tensor.mul, broadcastable=1)\n",
    "\n",
    "    gen_image = ElemwiseSumLayer([prior, posterior])\n",
    "\n",
    "    return gen_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotting image \n",
    "\n",
    "def plot_image(generated_image, epoch_val):\n",
    "    save_path = '/output/'\n",
    "    fig, axes1 = plt.subplots(5, 5, figsize=(4, 4))\n",
    "    # axes1.set_axis_off()\n",
    "    # axes1.imshow(reshaped_image[10])\n",
    "    # fig.imshow(reshaped_image[10])\n",
    "    gen_trans_image = generated_image.transpose(0, 2, 3, 1)\n",
    "    orig_trans_image = reshaped_image.transpose(0, 2, 3, 1)\n",
    "    img_h, img_w = (32, 32)\n",
    "    grid_shape = 8\n",
    "    grid_pad = 5\n",
    "    grid_h = img_h * grid_shape + grid_pad * (grid_shape - 1)\n",
    "    grid_w = img_w * grid_shape + grid_pad * (grid_shape - 1)\n",
    "    img_grid = np.zeros((grid_h, grid_w, 3), dtype=np.uint8)\n",
    "    %matplotlib inline\n",
    "    for j in range(5):\n",
    "        for k in range(5):\n",
    "            i = np.random.choice(range(len(gen_trans_image)))\n",
    "            axes1[j][k].set_axis_off()\n",
    "            deproc = ((gen_trans_image[i:i+1][0] + 1) * 127.5).astype(np.uint8)\n",
    "            axes1[j][k].imshow((deproc))\n",
    "        row = (j // grid_shape) * (img_h + grid_pad)\n",
    "        col = (j % grid_shape) * (img_w + grid_pad)\n",
    "\n",
    "        img_grid[row:row+img_h, col:col+img_w, :] = deproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM2's output is (100, 100)\n",
      "('Generator output:', (None, 128, 8, 8))\n",
      "('Generator output:', (None, 64, 16, 16))\n",
      "('Generator output:', (None, 3, 32, 32))\n",
      "('Generator output:', (100, 512, 4, 4))\n",
      "('Generator output:', (100, 256, 8, 8))\n",
      "('Generator output:', (100, 128, 16, 16))\n",
      "('Disc output:', (None, 96, 16, 16))\n",
      "('Disc output:', (None, 192, 8, 8))\n",
      "('Disc output:', (None, 192, 8, 8))\n",
      "('Disc output:', (None, 192))\n",
      "('Discriminator output:', (None, 1))\n",
      "Starting to compile functions\n",
      "done compiling training function\n",
      "done all compilation\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "\n",
    "batch_size = 100\n",
    "initial_lr = 4e-4\n",
    "l_r = theano.shared(lasagne.utils.floatX(initial_lr))\n",
    "batch_number = int(round(len(reshaped_image) / batch_size))\n",
    "\n",
    "def log_sum_exp(x, axis=1):\n",
    "    m = tensor.max(x, axis=axis)\n",
    "    return m + tensor.log(tensor.sum(tensor.exp(x-m.dimshuffle(0,'x')), axis=axis))\n",
    "\n",
    "# Noise assignment\n",
    "rng = np.random.RandomState(1)\n",
    "theano_rng = RandomStreams(rng.randint(2 ** 15))\n",
    "lasagne.random.set_rng(np.random.RandomState(rng.randint(2 ** 15)))\n",
    "noise_dim = (batch_size, 100)\n",
    "noise_fg = theano_rng.normal(size=noise_dim)\n",
    "noise_bg = theano_rng.normal(size=noise_dim)\n",
    "x_inp = tensor.tensor4('x_inp', dtype='float32')\n",
    "\n",
    "# Build the network\n",
    "gen = construct_gen(noise_bg, noise_fg, batch_size=batch_size)\n",
    "disc, features = build_desc(x_inp)\n",
    "\n",
    "# Output of discriminator with original images. training phase, so non deterministic\n",
    "disc_out = lasagne.layers.get_output(disc, x_inp, deterministic=False)\n",
    "gen_out = lasagne.layers.get_output(gen)\n",
    "disc_over_gen = lasagne.layers.get_output(disc, gen_out)\n",
    "true_features = lasagne.layers.get_output(features, x_inp)\n",
    "fake_features = lasagne.layers.get_output(features, gen_out)\n",
    "# Loss functions. 1) Gen's 2) Disc's for predicting correctly 3) Feature matching loss\n",
    "false_loss = log_sum_exp(disc_over_gen)\n",
    "truth_loss = log_sum_exp(disc_out)\n",
    "disc_loss = -0.5 * tensor.mean(truth_loss) + 0.5 * tensor.mean(tensor.nnet.softplus(truth_loss)) + 0.5 * tensor.mean(tensor.nnet.softplus(false_loss))\n",
    "gen_loss = tensor.mean(squared_error(tensor.mean(true_features, axis=0), tensor.mean(fake_features, axis=0)))\n",
    "\n",
    "# Fetch and Update params\n",
    "gen_params = lasagne.layers.get_all_params(gen, trainable=True)\n",
    "disc_params = lasagne.layers.get_all_params(disc, trainable=True)\n",
    "\n",
    "disc_updates = lasagne.updates.adam(disc_loss, disc_params, learning_rate=l_r, beta1=0.5)\n",
    "disc_param_avg = [theano.shared(np.cast[theano.config.floatX](0.* p.get_value())) for p in disc_params]\n",
    "disc_avg_updates = [(a, a + 0.0001 * (p - a)) for p, a in zip(disc_params, disc_param_avg)]\n",
    "gen_updates = lasagne.updates.adam(gen_loss, gen_params, learning_rate=l_r, beta1=0.5)\n",
    "\n",
    "\n",
    "# Compile theano functions\n",
    "print(\"Starting to compile functions\")\n",
    "train_disc = theano.function([x_inp], [disc_loss], updates=disc_updates)\n",
    "train_gen = theano.function(inputs=[x_inp], outputs=None, updates=gen_updates)\n",
    "print(\"done compiling training function\")\n",
    "# Functions for generating\n",
    "generate_im_func = theano.function([], gen_out)\n",
    "print(\"done all compilation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR GAN loss is [ 0.5677411]\n",
      "Finished 1 of 1000. Time taken 198.781s\n",
      "LR GAN loss is [ 0.58069515]\n",
      "Finished 2 of 1000. Time taken 198.779s\n",
      "LR GAN loss is [ 0.60611451]\n",
      "Finished 3 of 1000. Time taken 198.731s\n",
      "LR GAN loss is [ 0.59767008]\n",
      "Finished 4 of 1000. Time taken 199.176s\n",
      "LR GAN loss is [ 0.59383047]\n",
      "Finished 5 of 1000. Time taken 198.414s\n",
      "LR GAN loss is [ 0.59701282]\n",
      "Finished 6 of 1000. Time taken 199.140s\n",
      "LR GAN loss is [ 0.59290957]\n",
      "Finished 7 of 1000. Time taken 198.986s\n",
      "LR GAN loss is [ 0.5925737]\n",
      "Finished 8 of 1000. Time taken 199.219s\n",
      "LR GAN loss is [ 0.59848905]\n",
      "Finished 9 of 1000. Time taken 198.595s\n",
      "LR GAN loss is [ 0.59395051]\n",
      "Finished 10 of 1000. Time taken 198.722s\n",
      "LR GAN loss is [ 0.59546119]\n",
      "Finished 11 of 1000. Time taken 198.654s\n",
      "LR GAN loss is [ 0.595779]\n",
      "Finished 12 of 1000. Time taken 199.316s\n",
      "LR GAN loss is [ 0.59996909]\n",
      "Finished 13 of 1000. Time taken 199.302s\n",
      "LR GAN loss is [ 0.59131467]\n",
      "Finished 14 of 1000. Time taken 198.122s\n",
      "LR GAN loss is [ 0.59798127]\n",
      "Finished 15 of 1000. Time taken 198.415s\n",
      "LR GAN loss is [ 0.59957111]\n",
      "Finished 16 of 1000. Time taken 199.060s\n",
      "LR GAN loss is [ 0.61306936]\n",
      "Finished 17 of 1000. Time taken 198.585s\n",
      "LR GAN loss is [ 0.59451991]\n",
      "Finished 18 of 1000. Time taken 199.388s\n",
      "LR GAN loss is [ 0.5958668]\n",
      "Finished 19 of 1000. Time taken 198.536s\n",
      "LR GAN loss is [ 0.59085399]\n",
      "Finished 20 of 1000. Time taken 198.923s\n",
      "LR GAN loss is [ 0.59655881]\n",
      "Finished 21 of 1000. Time taken 198.958s\n",
      "LR GAN loss is [ 0.5922448]\n",
      "Finished 22 of 1000. Time taken 198.948s\n",
      "LR GAN loss is [ 0.5842557]\n",
      "Finished 23 of 1000. Time taken 198.952s\n",
      "LR GAN loss is [ 0.57567173]\n",
      "Finished 24 of 1000. Time taken 198.970s\n",
      "LR GAN loss is [ 0.58658057]\n",
      "Finished 25 of 1000. Time taken 198.676s\n",
      "LR GAN loss is [ 0.59048027]\n",
      "Finished 26 of 1000. Time taken 199.281s\n",
      "LR GAN loss is [ 0.58096606]\n",
      "Finished 27 of 1000. Time taken 198.385s\n",
      "LR GAN loss is [ 0.58842981]\n",
      "Finished 28 of 1000. Time taken 199.243s\n",
      "LR GAN loss is [ 0.58135539]\n",
      "Finished 29 of 1000. Time taken 199.331s\n",
      "LR GAN loss is [ 0.5754047]\n",
      "Finished 30 of 1000. Time taken 199.386s\n",
      "LR GAN loss is [ 0.58189124]\n",
      "Finished 31 of 1000. Time taken 199.105s\n",
      "LR GAN loss is [ 0.57126176]\n",
      "Finished 32 of 1000. Time taken 198.619s\n",
      "LR GAN loss is [ 0.578502]\n",
      "Finished 33 of 1000. Time taken 198.950s\n",
      "LR GAN loss is [ 0.57830763]\n",
      "Finished 34 of 1000. Time taken 198.670s\n",
      "LR GAN loss is [ 0.56950182]\n",
      "Finished 35 of 1000. Time taken 199.420s\n",
      "LR GAN loss is [ 0.56998932]\n",
      "Finished 36 of 1000. Time taken 198.097s\n",
      "LR GAN loss is [ 0.57455426]\n",
      "Finished 37 of 1000. Time taken 199.239s\n",
      "LR GAN loss is [ 0.56969172]\n",
      "Finished 38 of 1000. Time taken 198.428s\n",
      "LR GAN loss is [ 0.56704676]\n",
      "Finished 39 of 1000. Time taken 198.908s\n",
      "LR GAN loss is [ 0.56735766]\n",
      "Finished 40 of 1000. Time taken 198.388s\n",
      "LR GAN loss is [ 0.56613821]\n",
      "Finished 41 of 1000. Time taken 198.913s\n",
      "LR GAN loss is [ 0.56326753]\n",
      "Finished 42 of 1000. Time taken 198.226s\n",
      "LR GAN loss is [ 0.56332493]\n",
      "Finished 43 of 1000. Time taken 199.155s\n",
      "LR GAN loss is [ 0.56126451]\n",
      "Finished 44 of 1000. Time taken 199.003s\n",
      "LR GAN loss is [ 0.57669896]\n",
      "Finished 45 of 1000. Time taken 199.196s\n",
      "LR GAN loss is [ 0.55760312]\n",
      "Finished 46 of 1000. Time taken 198.884s\n",
      "LR GAN loss is [ 0.55736887]\n",
      "Finished 47 of 1000. Time taken 199.199s\n",
      "LR GAN loss is [ 0.55966973]\n",
      "Finished 48 of 1000. Time taken 198.672s\n",
      "LR GAN loss is [ 0.56047487]\n",
      "Finished 49 of 1000. Time taken 199.506s\n",
      "LR GAN loss is [ 0.55939049]\n",
      "Finished 50 of 1000. Time taken 199.688s\n",
      "LR GAN loss is [ 0.55945373]\n",
      "Finished 51 of 1000. Time taken 198.834s\n",
      "LR GAN loss is [ 0.56173718]\n",
      "Finished 52 of 1000. Time taken 198.732s\n",
      "LR GAN loss is [ 0.55144751]\n",
      "Finished 53 of 1000. Time taken 199.303s\n",
      "LR GAN loss is [ 0.5502907]\n",
      "Finished 54 of 1000. Time taken 198.224s\n",
      "LR GAN loss is [ 0.55289567]\n",
      "Finished 55 of 1000. Time taken 198.388s\n",
      "LR GAN loss is [ 0.54543418]\n",
      "Finished 56 of 1000. Time taken 198.579s\n",
      "LR GAN loss is [ 0.55256319]\n",
      "Finished 57 of 1000. Time taken 198.606s\n",
      "LR GAN loss is [ 0.54535317]\n",
      "Finished 58 of 1000. Time taken 198.891s\n",
      "LR GAN loss is [ 0.548751]\n",
      "Finished 59 of 1000. Time taken 198.413s\n",
      "LR GAN loss is [ 0.54741293]\n",
      "Finished 60 of 1000. Time taken 198.944s\n",
      "LR GAN loss is [ 0.54703194]\n",
      "Finished 61 of 1000. Time taken 198.697s\n",
      "LR GAN loss is [ 0.54739577]\n",
      "Finished 62 of 1000. Time taken 198.952s\n",
      "LR GAN loss is [ 0.54945672]\n",
      "Finished 63 of 1000. Time taken 198.754s\n",
      "LR GAN loss is [ 0.54258049]\n",
      "Finished 64 of 1000. Time taken 198.599s\n",
      "LR GAN loss is [ 0.54208791]\n",
      "Finished 65 of 1000. Time taken 198.872s\n",
      "LR GAN loss is [ 0.53982651]\n",
      "Finished 66 of 1000. Time taken 198.839s\n",
      "LR GAN loss is [ 0.53613734]\n",
      "Finished 67 of 1000. Time taken 199.477s\n",
      "LR GAN loss is [ 0.53700489]\n",
      "Finished 68 of 1000. Time taken 199.011s\n",
      "LR GAN loss is [ 0.54572886]\n",
      "Finished 69 of 1000. Time taken 198.395s\n",
      "LR GAN loss is [ 0.53196687]\n",
      "Finished 70 of 1000. Time taken 199.012s\n",
      "LR GAN loss is [ 0.53775072]\n",
      "Finished 71 of 1000. Time taken 199.218s\n",
      "LR GAN loss is [ 0.53713441]\n",
      "Finished 72 of 1000. Time taken 199.459s\n",
      "LR GAN loss is [ 0.54010659]\n",
      "Finished 73 of 1000. Time taken 198.588s\n",
      "LR GAN loss is [ 0.53870142]\n",
      "Finished 74 of 1000. Time taken 198.627s\n",
      "LR GAN loss is [ 0.53553307]\n",
      "Finished 75 of 1000. Time taken 199.664s\n",
      "LR GAN loss is [ 0.53436542]\n",
      "Finished 76 of 1000. Time taken 199.224s\n",
      "LR GAN loss is [ 0.53518695]\n",
      "Finished 77 of 1000. Time taken 198.331s\n",
      "LR GAN loss is [ 0.53745037]\n",
      "Finished 78 of 1000. Time taken 198.221s\n",
      "LR GAN loss is [ 0.53630418]\n",
      "Finished 79 of 1000. Time taken 199.181s\n",
      "LR GAN loss is [ 0.5405857]\n",
      "Finished 80 of 1000. Time taken 198.780s\n",
      "LR GAN loss is [ 0.53284425]\n",
      "Finished 81 of 1000. Time taken 198.615s\n",
      "LR GAN loss is [ 0.53950083]\n",
      "Finished 82 of 1000. Time taken 198.907s\n",
      "LR GAN loss is [ 0.53523558]\n",
      "Finished 83 of 1000. Time taken 198.576s\n",
      "LR GAN loss is [ 0.54147744]\n",
      "Finished 84 of 1000. Time taken 198.512s\n",
      "LR GAN loss is [ 0.54010773]\n",
      "Finished 85 of 1000. Time taken 198.339s\n",
      "LR GAN loss is [ 0.53456813]\n",
      "Finished 86 of 1000. Time taken 198.500s\n",
      "LR GAN loss is [ 0.53608525]\n",
      "Finished 87 of 1000. Time taken 199.101s\n",
      "LR GAN loss is [ 0.53317767]\n",
      "Finished 88 of 1000. Time taken 198.022s\n",
      "LR GAN loss is [ 0.53323531]\n",
      "Finished 89 of 1000. Time taken 198.132s\n",
      "LR GAN loss is [ 0.54056984]\n",
      "Finished 90 of 1000. Time taken 198.830s\n",
      "LR GAN loss is [ 0.53696668]\n",
      "Finished 91 of 1000. Time taken 198.344s\n",
      "LR GAN loss is [ 0.531941]\n",
      "Finished 92 of 1000. Time taken 198.883s\n",
      "LR GAN loss is [ 0.53635663]\n",
      "Finished 93 of 1000. Time taken 198.591s\n",
      "LR GAN loss is [ 0.52985543]\n",
      "Finished 94 of 1000. Time taken 198.881s\n",
      "LR GAN loss is [ 0.53272814]\n",
      "Finished 95 of 1000. Time taken 198.662s\n",
      "LR GAN loss is [ 0.53534907]\n",
      "Finished 96 of 1000. Time taken 199.355s\n",
      "LR GAN loss is [ 0.53121829]\n",
      "Finished 97 of 1000. Time taken 198.676s\n",
      "LR GAN loss is [ 0.53188235]\n",
      "Finished 98 of 1000. Time taken 198.421s\n",
      "LR GAN loss is [ 0.53139037]\n",
      "Finished 99 of 1000. Time taken 198.620s\n",
      "LR GAN loss is [ 0.52546126]\n",
      "Finished 100 of 1000. Time taken 199.218s\n",
      "LR GAN loss is [ 0.53158134]\n",
      "Finished 101 of 1000. Time taken 198.486s\n",
      "LR GAN loss is [ 0.53085124]\n",
      "Finished 102 of 1000. Time taken 199.087s\n",
      "LR GAN loss is [ 0.53412616]\n",
      "Finished 103 of 1000. Time taken 197.794s\n",
      "LR GAN loss is [ 0.5354622]\n",
      "Finished 104 of 1000. Time taken 199.344s\n",
      "LR GAN loss is [ 0.53029203]\n",
      "Finished 105 of 1000. Time taken 198.631s\n",
      "LR GAN loss is [ 0.52978051]\n",
      "Finished 106 of 1000. Time taken 199.113s\n",
      "LR GAN loss is [ 0.53055316]\n",
      "Finished 107 of 1000. Time taken 199.139s\n",
      "LR GAN loss is [ 0.52640438]\n",
      "Finished 108 of 1000. Time taken 199.105s\n",
      "LR GAN loss is [ 0.53027838]\n",
      "Finished 109 of 1000. Time taken 199.283s\n",
      "LR GAN loss is [ 0.52759898]\n",
      "Finished 110 of 1000. Time taken 199.187s\n",
      "LR GAN loss is [ 0.53092563]\n",
      "Finished 111 of 1000. Time taken 199.798s\n",
      "LR GAN loss is [ 0.52734953]\n",
      "Finished 112 of 1000. Time taken 198.883s\n",
      "LR GAN loss is [ 0.5329197]\n",
      "Finished 113 of 1000. Time taken 198.615s\n",
      "LR GAN loss is [ 0.52766752]\n",
      "Finished 114 of 1000. Time taken 198.842s\n",
      "LR GAN loss is [ 0.52512372]\n",
      "Finished 115 of 1000. Time taken 199.311s\n",
      "LR GAN loss is [ 0.53085804]\n",
      "Finished 116 of 1000. Time taken 198.527s\n",
      "LR GAN loss is [ 0.53031462]\n",
      "Finished 117 of 1000. Time taken 198.385s\n",
      "LR GAN loss is [ 0.52164012]\n",
      "Finished 118 of 1000. Time taken 198.060s\n",
      "LR GAN loss is [ 0.5286262]\n",
      "Finished 119 of 1000. Time taken 198.990s\n",
      "LR GAN loss is [ 0.53156525]\n",
      "Finished 120 of 1000. Time taken 198.819s\n",
      "LR GAN loss is [ 0.52755207]\n",
      "Finished 121 of 1000. Time taken 198.944s\n",
      "LR GAN loss is [ 0.53400588]\n",
      "Finished 122 of 1000. Time taken 199.499s\n",
      "LR GAN loss is [ 0.52914643]\n",
      "Finished 123 of 1000. Time taken 199.851s\n",
      "LR GAN loss is [ 0.52772439]\n",
      "Finished 124 of 1000. Time taken 199.364s\n",
      "LR GAN loss is [ 0.52487469]\n",
      "Finished 125 of 1000. Time taken 198.373s\n",
      "LR GAN loss is [ 0.5300923]\n",
      "Finished 126 of 1000. Time taken 198.843s\n",
      "LR GAN loss is [ 0.52703786]\n",
      "Finished 127 of 1000. Time taken 199.466s\n",
      "LR GAN loss is [ 0.52300906]\n",
      "Finished 128 of 1000. Time taken 198.426s\n",
      "LR GAN loss is [ 0.52710772]\n",
      "Finished 129 of 1000. Time taken 198.835s\n",
      "LR GAN loss is [ 0.52397805]\n",
      "Finished 130 of 1000. Time taken 198.821s\n",
      "LR GAN loss is [ 0.52583551]\n",
      "Finished 131 of 1000. Time taken 198.817s\n",
      "LR GAN loss is [ 0.53128564]\n",
      "Finished 132 of 1000. Time taken 199.732s\n",
      "LR GAN loss is [ 0.52688277]\n",
      "Finished 133 of 1000. Time taken 199.487s\n",
      "LR GAN loss is [ 0.52516919]\n",
      "Finished 134 of 1000. Time taken 198.887s\n",
      "LR GAN loss is [ 0.51887685]\n",
      "Finished 135 of 1000. Time taken 198.440s\n",
      "LR GAN loss is [ 0.51708484]\n",
      "Finished 136 of 1000. Time taken 199.159s\n",
      "LR GAN loss is [ 0.52562267]\n",
      "Finished 137 of 1000. Time taken 198.533s\n",
      "LR GAN loss is [ 0.52703917]\n",
      "Finished 138 of 1000. Time taken 198.889s\n",
      "LR GAN loss is [ 0.51907337]\n",
      "Finished 139 of 1000. Time taken 198.749s\n",
      "LR GAN loss is [ 0.52664673]\n",
      "Finished 140 of 1000. Time taken 198.186s\n",
      "LR GAN loss is [ 0.52495015]\n",
      "Finished 141 of 1000. Time taken 199.078s\n",
      "LR GAN loss is [ 0.52324498]\n",
      "Finished 142 of 1000. Time taken 198.125s\n",
      "LR GAN loss is [ 0.52463943]\n",
      "Finished 143 of 1000. Time taken 199.138s\n",
      "LR GAN loss is [ 0.52185041]\n",
      "Finished 144 of 1000. Time taken 198.726s\n",
      "LR GAN loss is [ 0.52148968]\n",
      "Finished 145 of 1000. Time taken 198.992s\n",
      "LR GAN loss is [ 0.52339691]\n",
      "Finished 146 of 1000. Time taken 198.941s\n",
      "LR GAN loss is [ 0.52804136]\n",
      "Finished 147 of 1000. Time taken 199.179s\n",
      "LR GAN loss is [ 0.5249449]\n",
      "Finished 148 of 1000. Time taken 198.598s\n",
      "LR GAN loss is [ 0.52580792]\n",
      "Finished 149 of 1000. Time taken 198.540s\n",
      "LR GAN loss is [ 0.5247767]\n",
      "Finished 150 of 1000. Time taken 199.011s\n",
      "LR GAN loss is [ 0.52092046]\n",
      "Finished 151 of 1000. Time taken 199.519s\n",
      "LR GAN loss is [ 0.52157575]\n",
      "Finished 152 of 1000. Time taken 199.809s\n",
      "LR GAN loss is [ 0.52421379]\n",
      "Finished 153 of 1000. Time taken 198.866s\n",
      "LR GAN loss is [ 0.52512991]\n",
      "Finished 154 of 1000. Time taken 198.942s\n",
      "LR GAN loss is [ 0.52590662]\n",
      "Finished 155 of 1000. Time taken 199.338s\n",
      "LR GAN loss is [ 0.52751058]\n",
      "Finished 156 of 1000. Time taken 198.579s\n",
      "LR GAN loss is [ 0.5272314]\n",
      "Finished 157 of 1000. Time taken 198.548s\n",
      "LR GAN loss is [ 0.52662814]\n",
      "Finished 158 of 1000. Time taken 198.503s\n",
      "LR GAN loss is [ 0.52469963]\n",
      "Finished 159 of 1000. Time taken 198.507s\n",
      "LR GAN loss is [ 0.52522677]\n",
      "Finished 160 of 1000. Time taken 198.672s\n",
      "LR GAN loss is [ 0.52874714]\n",
      "Finished 161 of 1000. Time taken 198.854s\n",
      "LR GAN loss is [ 0.52624029]\n",
      "Finished 162 of 1000. Time taken 199.173s\n",
      "LR GAN loss is [ 0.52469611]\n",
      "Finished 163 of 1000. Time taken 198.951s\n",
      "LR GAN loss is [ 0.52409935]\n",
      "Finished 164 of 1000. Time taken 198.972s\n",
      "LR GAN loss is [ 0.51948851]\n",
      "Finished 165 of 1000. Time taken 198.720s\n",
      "LR GAN loss is [ 0.52058202]\n",
      "Finished 166 of 1000. Time taken 198.539s\n",
      "LR GAN loss is [ 0.52217269]\n",
      "Finished 167 of 1000. Time taken 198.707s\n",
      "LR GAN loss is [ 0.52023733]\n",
      "Finished 168 of 1000. Time taken 199.297s\n",
      "LR GAN loss is [ 0.51963264]\n",
      "Finished 169 of 1000. Time taken 198.633s\n",
      "LR GAN loss is [ 0.52139133]\n",
      "Finished 170 of 1000. Time taken 198.588s\n",
      "LR GAN loss is [ 0.52388191]\n",
      "Finished 171 of 1000. Time taken 198.876s\n",
      "LR GAN loss is [ 0.52171052]\n",
      "Finished 172 of 1000. Time taken 199.090s\n",
      "LR GAN loss is [ 0.52570403]\n",
      "Finished 173 of 1000. Time taken 199.001s\n",
      "LR GAN loss is [ 0.52306569]\n",
      "Finished 174 of 1000. Time taken 198.716s\n",
      "LR GAN loss is [ 0.52484667]\n",
      "Finished 175 of 1000. Time taken 198.642s\n",
      "LR GAN loss is [ 0.52462471]\n",
      "Finished 176 of 1000. Time taken 198.827s\n",
      "LR GAN loss is [ 0.52590913]\n",
      "Finished 177 of 1000. Time taken 199.153s\n",
      "LR GAN loss is [ 0.52133662]\n",
      "Finished 178 of 1000. Time taken 199.211s\n",
      "LR GAN loss is [ 0.52050835]\n",
      "Finished 179 of 1000. Time taken 198.960s\n",
      "LR GAN loss is [ 0.51966864]\n",
      "Finished 180 of 1000. Time taken 199.022s\n",
      "LR GAN loss is [ 0.51851541]\n",
      "Finished 181 of 1000. Time taken 198.199s\n",
      "LR GAN loss is [ 0.51725465]\n",
      "Finished 182 of 1000. Time taken 199.066s\n",
      "LR GAN loss is [ 0.52118081]\n",
      "Finished 183 of 1000. Time taken 199.241s\n",
      "LR GAN loss is [ 0.52237916]\n",
      "Finished 184 of 1000. Time taken 198.398s\n",
      "LR GAN loss is [ 0.52600342]\n",
      "Finished 185 of 1000. Time taken 198.597s\n",
      "LR GAN loss is [ 0.51882327]\n",
      "Finished 186 of 1000. Time taken 198.915s\n",
      "LR GAN loss is [ 0.52134818]\n",
      "Finished 187 of 1000. Time taken 199.137s\n",
      "LR GAN loss is [ 0.52295673]\n",
      "Finished 188 of 1000. Time taken 199.287s\n",
      "LR GAN loss is [ 0.52013677]\n",
      "Finished 189 of 1000. Time taken 198.558s\n",
      "LR GAN loss is [ 0.52521008]\n",
      "Finished 190 of 1000. Time taken 198.254s\n",
      "LR GAN loss is [ 0.52078646]\n",
      "Finished 191 of 1000. Time taken 199.143s\n",
      "LR GAN loss is [ 0.5224995]\n",
      "Finished 192 of 1000. Time taken 198.700s\n",
      "LR GAN loss is [ 0.51958501]\n",
      "Finished 193 of 1000. Time taken 198.965s\n",
      "LR GAN loss is [ 0.52018595]\n",
      "Finished 194 of 1000. Time taken 198.803s\n",
      "LR GAN loss is [ 0.52509171]\n",
      "Finished 195 of 1000. Time taken 199.538s\n",
      "LR GAN loss is [ 0.51873249]\n",
      "Finished 196 of 1000. Time taken 198.836s\n",
      "LR GAN loss is [ 0.51722342]\n",
      "Finished 197 of 1000. Time taken 198.952s\n",
      "LR GAN loss is [ 0.5212056]\n",
      "Finished 198 of 1000. Time taken 198.314s\n",
      "LR GAN loss is [ 0.52617967]\n",
      "Finished 199 of 1000. Time taken 198.366s\n",
      "LR GAN loss is [ 0.52200764]\n",
      "Finished 200 of 1000. Time taken 200.208s\n",
      "LR GAN loss is [ 0.52657789]\n",
      "Finished 201 of 1000. Time taken 199.499s\n",
      "LR GAN loss is [ 0.52718961]\n",
      "Finished 202 of 1000. Time taken 198.401s\n",
      "LR GAN loss is [ 0.52031803]\n",
      "Finished 203 of 1000. Time taken 198.377s\n",
      "LR GAN loss is [ 0.52322233]\n",
      "Finished 204 of 1000. Time taken 198.929s\n",
      "LR GAN loss is [ 0.52139252]\n",
      "Finished 205 of 1000. Time taken 199.006s\n",
      "LR GAN loss is [ 0.51843202]\n",
      "Finished 206 of 1000. Time taken 198.852s\n",
      "LR GAN loss is [ 0.52197248]\n",
      "Finished 207 of 1000. Time taken 197.970s\n",
      "LR GAN loss is [ 0.52332765]\n",
      "Finished 208 of 1000. Time taken 198.716s\n",
      "LR GAN loss is [ 0.52422118]\n",
      "Finished 209 of 1000. Time taken 198.813s\n",
      "LR GAN loss is [ 0.52151752]\n",
      "Finished 210 of 1000. Time taken 199.354s\n",
      "LR GAN loss is [ 0.5217737]\n",
      "Finished 211 of 1000. Time taken 199.406s\n",
      "LR GAN loss is [ 0.52107096]\n",
      "Finished 212 of 1000. Time taken 198.991s\n",
      "LR GAN loss is [ 0.52093905]\n",
      "Finished 213 of 1000. Time taken 198.161s\n",
      "LR GAN loss is [ 0.51995254]\n",
      "Finished 214 of 1000. Time taken 198.975s\n",
      "LR GAN loss is [ 0.52494025]\n",
      "Finished 215 of 1000. Time taken 198.211s\n",
      "LR GAN loss is [ 0.51846999]\n",
      "Finished 216 of 1000. Time taken 198.781s\n",
      "LR GAN loss is [ 0.51599324]\n",
      "Finished 217 of 1000. Time taken 198.794s\n",
      "LR GAN loss is [ 0.52330476]\n",
      "Finished 218 of 1000. Time taken 199.141s\n",
      "LR GAN loss is [ 0.51832867]\n",
      "Finished 219 of 1000. Time taken 198.871s\n",
      "LR GAN loss is [ 0.51866317]\n",
      "Finished 220 of 1000. Time taken 198.451s\n",
      "LR GAN loss is [ 0.52186555]\n",
      "Finished 221 of 1000. Time taken 197.676s\n",
      "LR GAN loss is [ 0.51737475]\n",
      "Finished 222 of 1000. Time taken 197.047s\n",
      "LR GAN loss is [ 0.52343071]\n",
      "Finished 223 of 1000. Time taken 197.894s\n",
      "LR GAN loss is [ 0.52173525]\n",
      "Finished 224 of 1000. Time taken 198.295s\n",
      "LR GAN loss is [ 0.51857716]\n",
      "Finished 225 of 1000. Time taken 198.556s\n",
      "LR GAN loss is [ 0.51652455]\n",
      "Finished 226 of 1000. Time taken 197.521s\n",
      "LR GAN loss is [ 0.51893681]\n",
      "Finished 227 of 1000. Time taken 198.450s\n",
      "LR GAN loss is [ 0.51808167]\n",
      "Finished 228 of 1000. Time taken 198.097s\n",
      "LR GAN loss is [ 0.52219605]\n",
      "Finished 229 of 1000. Time taken 197.713s\n",
      "LR GAN loss is [ 0.52147245]\n",
      "Finished 230 of 1000. Time taken 198.782s\n",
      "LR GAN loss is [ 0.51931578]\n",
      "Finished 231 of 1000. Time taken 198.615s\n",
      "LR GAN loss is [ 0.51964182]\n",
      "Finished 232 of 1000. Time taken 198.628s\n",
      "LR GAN loss is [ 0.51748157]\n",
      "Finished 233 of 1000. Time taken 198.338s\n",
      "LR GAN loss is [ 0.52562159]\n",
      "Finished 234 of 1000. Time taken 198.772s\n",
      "LR GAN loss is [ 0.52082264]\n",
      "Finished 235 of 1000. Time taken 198.190s\n",
      "LR GAN loss is [ 0.52147466]\n",
      "Finished 236 of 1000. Time taken 198.348s\n",
      "LR GAN loss is [ 0.51832324]\n",
      "Finished 237 of 1000. Time taken 198.874s\n",
      "LR GAN loss is [ 0.52288586]\n",
      "Finished 238 of 1000. Time taken 198.325s\n",
      "LR GAN loss is [ 0.52643985]\n",
      "Finished 239 of 1000. Time taken 198.377s\n",
      "LR GAN loss is [ 0.52185887]\n",
      "Finished 240 of 1000. Time taken 198.354s\n",
      "LR GAN loss is [ 0.5242064]\n",
      "Finished 241 of 1000. Time taken 198.332s\n",
      "LR GAN loss is [ 0.51886356]\n",
      "Finished 242 of 1000. Time taken 198.419s\n",
      "LR GAN loss is [ 0.51774478]\n",
      "Finished 243 of 1000. Time taken 197.741s\n",
      "LR GAN loss is [ 0.52209908]\n",
      "Finished 244 of 1000. Time taken 198.318s\n",
      "LR GAN loss is [ 0.52197897]\n",
      "Finished 245 of 1000. Time taken 198.291s\n",
      "LR GAN loss is [ 0.52105814]\n",
      "Finished 246 of 1000. Time taken 198.735s\n",
      "LR GAN loss is [ 0.52128637]\n",
      "Finished 247 of 1000. Time taken 198.358s\n",
      "LR GAN loss is [ 0.5206008]\n",
      "Finished 248 of 1000. Time taken 198.297s\n",
      "LR GAN loss is [ 0.51500428]\n",
      "Finished 249 of 1000. Time taken 199.311s\n",
      "LR GAN loss is [ 0.51706356]\n",
      "Finished 250 of 1000. Time taken 198.244s\n",
      "LR GAN loss is [ 0.51654446]\n",
      "Finished 251 of 1000. Time taken 198.204s\n",
      "LR GAN loss is [ 0.51651776]\n",
      "Finished 252 of 1000. Time taken 198.487s\n",
      "LR GAN loss is [ 0.51748252]\n",
      "Finished 253 of 1000. Time taken 198.860s\n",
      "LR GAN loss is [ 0.52092838]\n",
      "Finished 254 of 1000. Time taken 197.891s\n",
      "LR GAN loss is [ 0.52128029]\n",
      "Finished 255 of 1000. Time taken 198.277s\n",
      "LR GAN loss is [ 0.51995856]\n",
      "Finished 256 of 1000. Time taken 198.459s\n",
      "LR GAN loss is [ 0.51991504]\n",
      "Finished 257 of 1000. Time taken 198.479s\n",
      "LR GAN loss is [ 0.52450001]\n",
      "Finished 258 of 1000. Time taken 199.137s\n",
      "LR GAN loss is [ 0.52250451]\n",
      "Finished 259 of 1000. Time taken 198.712s\n",
      "LR GAN loss is [ 0.51880568]\n",
      "Finished 260 of 1000. Time taken 197.942s\n",
      "LR GAN loss is [ 0.52199119]\n",
      "Finished 261 of 1000. Time taken 198.532s\n",
      "LR GAN loss is [ 0.51601523]\n",
      "Finished 262 of 1000. Time taken 198.077s\n",
      "LR GAN loss is [ 0.5211603]\n",
      "Finished 263 of 1000. Time taken 197.861s\n",
      "LR GAN loss is [ 0.52027082]\n",
      "Finished 264 of 1000. Time taken 198.360s\n",
      "LR GAN loss is [ 0.52274728]\n",
      "Finished 265 of 1000. Time taken 198.201s\n",
      "LR GAN loss is [ 0.52341247]\n",
      "Finished 266 of 1000. Time taken 198.102s\n",
      "LR GAN loss is [ 0.51839548]\n",
      "Finished 267 of 1000. Time taken 198.279s\n",
      "LR GAN loss is [ 0.51982218]\n",
      "Finished 268 of 1000. Time taken 198.920s\n",
      "LR GAN loss is [ 0.51785594]\n",
      "Finished 269 of 1000. Time taken 198.242s\n",
      "LR GAN loss is [ 0.52170491]\n",
      "Finished 270 of 1000. Time taken 198.986s\n",
      "LR GAN loss is [ 0.52427477]\n",
      "Finished 271 of 1000. Time taken 197.811s\n",
      "LR GAN loss is [ 0.52155674]\n",
      "Finished 272 of 1000. Time taken 198.325s\n",
      "LR GAN loss is [ 0.51915056]\n",
      "Finished 273 of 1000. Time taken 198.736s\n",
      "LR GAN loss is [ 0.52589017]\n",
      "Finished 274 of 1000. Time taken 198.598s\n",
      "LR GAN loss is [ 0.52103049]\n",
      "Finished 275 of 1000. Time taken 197.829s\n",
      "LR GAN loss is [ 0.52302289]\n",
      "Finished 276 of 1000. Time taken 198.578s\n",
      "LR GAN loss is [ 0.51885319]\n",
      "Finished 277 of 1000. Time taken 198.276s\n",
      "LR GAN loss is [ 0.52503109]\n",
      "Finished 278 of 1000. Time taken 197.970s\n",
      "LR GAN loss is [ 0.52019405]\n",
      "Finished 279 of 1000. Time taken 198.743s\n",
      "LR GAN loss is [ 0.5218358]\n",
      "Finished 280 of 1000. Time taken 199.042s\n",
      "LR GAN loss is [ 0.51675284]\n",
      "Finished 281 of 1000. Time taken 198.712s\n",
      "LR GAN loss is [ 0.5161047]\n",
      "Finished 282 of 1000. Time taken 198.538s\n",
      "LR GAN loss is [ 0.51922065]\n",
      "Finished 283 of 1000. Time taken 197.654s\n",
      "LR GAN loss is [ 0.51965117]\n",
      "Finished 284 of 1000. Time taken 198.336s\n",
      "LR GAN loss is [ 0.52103001]\n",
      "Finished 285 of 1000. Time taken 198.195s\n",
      "LR GAN loss is [ 0.52134097]\n",
      "Finished 286 of 1000. Time taken 197.830s\n",
      "LR GAN loss is [ 0.52120996]\n",
      "Finished 287 of 1000. Time taken 198.632s\n",
      "LR GAN loss is [ 0.52073693]\n",
      "Finished 288 of 1000. Time taken 198.395s\n",
      "LR GAN loss is [ 0.5169757]\n",
      "Finished 289 of 1000. Time taken 198.495s\n",
      "LR GAN loss is [ 0.51555693]\n",
      "Finished 290 of 1000. Time taken 198.313s\n",
      "LR GAN loss is [ 0.51466519]\n",
      "Finished 291 of 1000. Time taken 198.020s\n",
      "LR GAN loss is [ 0.51801181]\n",
      "Finished 292 of 1000. Time taken 197.984s\n",
      "LR GAN loss is [ 0.52633727]\n",
      "Finished 293 of 1000. Time taken 198.179s\n",
      "LR GAN loss is [ 0.51551807]\n",
      "Finished 294 of 1000. Time taken 198.049s\n",
      "LR GAN loss is [ 0.5225457]\n",
      "Finished 295 of 1000. Time taken 198.436s\n",
      "LR GAN loss is [ 0.51934028]\n",
      "Finished 296 of 1000. Time taken 198.863s\n",
      "LR GAN loss is [ 0.52108812]\n",
      "Finished 297 of 1000. Time taken 198.160s\n",
      "LR GAN loss is [ 0.51566094]\n",
      "Finished 298 of 1000. Time taken 197.883s\n",
      "LR GAN loss is [ 0.51803917]\n",
      "Finished 299 of 1000. Time taken 197.864s\n",
      "LR GAN loss is [ 0.51603341]\n",
      "Finished 300 of 1000. Time taken 198.436s\n",
      "LR GAN loss is [ 0.52114111]\n",
      "Finished 301 of 1000. Time taken 197.948s\n",
      "LR GAN loss is [ 0.51691329]\n",
      "Finished 302 of 1000. Time taken 197.985s\n",
      "LR GAN loss is [ 0.52288711]\n",
      "Finished 303 of 1000. Time taken 198.727s\n",
      "LR GAN loss is [ 0.52153075]\n",
      "Finished 304 of 1000. Time taken 199.121s\n",
      "LR GAN loss is [ 0.52302986]\n",
      "Finished 305 of 1000. Time taken 198.735s\n",
      "LR GAN loss is [ 0.5212785]\n",
      "Finished 306 of 1000. Time taken 199.112s\n",
      "LR GAN loss is [ 0.51883179]\n",
      "Finished 307 of 1000. Time taken 198.246s\n",
      "LR GAN loss is [ 0.51516026]\n",
      "Finished 308 of 1000. Time taken 197.917s\n",
      "LR GAN loss is [ 0.51556498]\n",
      "Finished 309 of 1000. Time taken 197.903s\n",
      "LR GAN loss is [ 0.51862276]\n",
      "Finished 310 of 1000. Time taken 198.603s\n",
      "LR GAN loss is [ 0.52363414]\n",
      "Finished 311 of 1000. Time taken 198.307s\n",
      "LR GAN loss is [ 0.5184505]\n",
      "Finished 312 of 1000. Time taken 197.988s\n",
      "LR GAN loss is [ 0.5161708]\n",
      "Finished 313 of 1000. Time taken 198.481s\n",
      "LR GAN loss is [ 0.52028579]\n",
      "Finished 314 of 1000. Time taken 198.552s\n",
      "LR GAN loss is [ 0.52121419]\n",
      "Finished 315 of 1000. Time taken 198.306s\n",
      "LR GAN loss is [ 0.52108914]\n",
      "Finished 316 of 1000. Time taken 199.094s\n",
      "LR GAN loss is [ 0.52627099]\n",
      "Finished 317 of 1000. Time taken 198.043s\n",
      "LR GAN loss is [ 0.52226961]\n",
      "Finished 318 of 1000. Time taken 198.874s\n",
      "LR GAN loss is [ 0.5205847]\n",
      "Finished 319 of 1000. Time taken 198.691s\n",
      "LR GAN loss is [ 0.5196715]\n",
      "Finished 320 of 1000. Time taken 198.149s\n",
      "LR GAN loss is [ 0.51801485]\n",
      "Finished 321 of 1000. Time taken 198.912s\n",
      "LR GAN loss is [ 0.52307123]\n",
      "Finished 322 of 1000. Time taken 197.852s\n",
      "LR GAN loss is [ 0.51699424]\n",
      "Finished 323 of 1000. Time taken 198.349s\n",
      "LR GAN loss is [ 0.5259133]\n",
      "Finished 324 of 1000. Time taken 198.688s\n",
      "LR GAN loss is [ 0.52664906]\n",
      "Finished 325 of 1000. Time taken 198.351s\n",
      "LR GAN loss is [ 0.52085423]\n",
      "Finished 326 of 1000. Time taken 198.924s\n",
      "LR GAN loss is [ 0.51848787]\n",
      "Finished 327 of 1000. Time taken 197.892s\n",
      "LR GAN loss is [ 0.51963538]\n",
      "Finished 328 of 1000. Time taken 196.996s\n",
      "LR GAN loss is [ 0.51844019]\n",
      "Finished 329 of 1000. Time taken 198.362s\n",
      "LR GAN loss is [ 0.51896471]\n",
      "Finished 330 of 1000. Time taken 198.415s\n",
      "LR GAN loss is [ 0.51820612]\n",
      "Finished 331 of 1000. Time taken 198.357s\n",
      "LR GAN loss is [ 0.51965308]\n",
      "Finished 332 of 1000. Time taken 198.339s\n",
      "LR GAN loss is [ 0.51947439]\n",
      "Finished 333 of 1000. Time taken 197.705s\n",
      "LR GAN loss is [ 0.5154165]\n",
      "Finished 334 of 1000. Time taken 198.696s\n",
      "LR GAN loss is [ 0.52405566]\n",
      "Finished 335 of 1000. Time taken 198.929s\n",
      "LR GAN loss is [ 0.52544487]\n",
      "Finished 336 of 1000. Time taken 197.898s\n",
      "LR GAN loss is [ 0.52312779]\n",
      "Finished 337 of 1000. Time taken 198.517s\n",
      "LR GAN loss is [ 0.52185607]\n",
      "Finished 338 of 1000. Time taken 198.358s\n",
      "LR GAN loss is [ 0.52461112]\n",
      "Finished 339 of 1000. Time taken 197.854s\n",
      "LR GAN loss is [ 0.52178127]\n",
      "Finished 340 of 1000. Time taken 198.329s\n",
      "LR GAN loss is [ 0.52389741]\n",
      "Finished 341 of 1000. Time taken 197.903s\n",
      "LR GAN loss is [ 0.51856381]\n",
      "Finished 342 of 1000. Time taken 197.566s\n",
      "LR GAN loss is [ 0.52177858]\n",
      "Finished 343 of 1000. Time taken 198.843s\n",
      "LR GAN loss is [ 0.52296734]\n",
      "Finished 344 of 1000. Time taken 198.306s\n",
      "LR GAN loss is [ 0.52563435]\n",
      "Finished 345 of 1000. Time taken 197.722s\n",
      "LR GAN loss is [ 0.51768303]\n",
      "Finished 346 of 1000. Time taken 198.768s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-d330986658f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mshuffled_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshaped_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreshaped_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreshaped_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_disc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mtrain_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moffset\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "import time\n",
    "output_path = '/output/'\n",
    "for ep in range(num_epochs):\n",
    "    # create batches problematicand train\n",
    "    # Batch size is 128, so 220\n",
    "    begin = time.time()\n",
    "    offset = 0\n",
    "    loss = 0\n",
    "\n",
    "    for num_iter, bn in enumerate(range(batch_number)):\n",
    "        # Randomly shuffle inputs\n",
    "        shuffled_inputs = reshaped_image[np.random.randint(len(reshaped_image), size=len(reshaped_image)), :, :, :]\n",
    "        inputs = normalise(shuffled_inputs[offset:offset + batch_size])\n",
    "        loss += np.array(train_disc(inputs))\n",
    "        train_gen(inputs)\n",
    "        offset += batch_size\n",
    "    end = time.time()\n",
    "    print(\"LR GAN loss is \" + str(loss / np.float32(batch_number)))\n",
    "    print(\"Finished {} of {}. Time taken {:.3f}s\".format(ep + 1, num_epochs,  end - begin))\n",
    "\n",
    "    # PLot the image generated for every 50epochs\n",
    "    if ep % 100 == 0:\n",
    "        generated_image = generate_im_func()\n",
    "        plot_image(generated_image, ep)\n",
    "\n",
    "    # Degrading the learning rate\n",
    "    if ep >= num_epochs // 3:\n",
    "        progress = float(ep) / num_epochs\n",
    "        l_r.set_value(lasagne.utils.floatX(initial_lr*2*(1 - progress)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez(output_path + 'cifar_gen.npz', *lasagne.layers.get_all_param_values(gen))\n",
    "np.savez(output_path + 'cifar_disc.npz', *lasagne.layers.get_all_param_values(disc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Restoring the weights\n",
    "disc_w = np.load('/Users/Ramana/Documents/Results/weights/cifar_disc600.npz')\n",
    "mod_d_w = sorted(disc_w.keys(), key=lambda s: int(s.split('_')[-1]))\n",
    "mod_disc_w = []\n",
    "\n",
    "for j001 in range(len(mod_d_w)):\n",
    "    mod_disc_w.append(disc_w[mod_d_w[j001]])\n",
    "lasagne.layers.set_all_param_values(disc, mod_disc_w)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
